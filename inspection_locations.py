{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspection Location Data\n",
    "# This script uses the Foursquare API to fetch data for food locations that will be used in the route optimizer\n",
    "\n",
    "import config\n",
    "import requests\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Makes Foursquare API call and cleans the data that is returned.\n",
    "    \n",
    "    Output:\n",
    "    inspection_locations.csv file is exported to the working directory\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    version = '20200331'  # Date version of the API being used\n",
    "    near = 'Salt Lake City, UT'  # String name, state combo of a geocodable location\n",
    "    radius = 16093.4  # 10 miles in meters\n",
    "    limit = 100  # Number of results\n",
    "    section = 'food'  # General category of results\n",
    "    time = 'any'  # Any time of day (not the time the request is made)\n",
    "    day = 'any'  # Any day of the week (not the time the request is made)\n",
    "\n",
    "    # Create API call URL\n",
    "    url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&near={}&radius={}&limit={}&section={}&time={}&day={}'.format(\n",
    "        config.api_key, \n",
    "        config.api_secret, \n",
    "        version, \n",
    "        near,\n",
    "        radius, \n",
    "        limit,\n",
    "        section,\n",
    "        time,\n",
    "        day)\n",
    "\n",
    "    # Make the API call\n",
    "    results = requests.get(url).json()\n",
    "\n",
    "    # Remove unneeded JSON data\n",
    "    venues = results['response']['groups'][0]['items']\n",
    "\n",
    "    # Flatten the JSON file into a dataframe\n",
    "    inspection_locations = json_normalize(venues)\n",
    "\n",
    "    # Remove unneeded columns from dataframe\n",
    "    inspection_locations = inspection_locations.iloc[:,np.r_[4:8,9,11:13]]\n",
    "\n",
    "    # Remove extra characters from column names\n",
    "    clean_col_names = []\n",
    "\n",
    "    for column in inspection_locations.columns:\n",
    "        new_col = column.rsplit(\".\", 1)\n",
    "        new_col = new_col[-1]\n",
    "        clean_col_names.append(new_col)\n",
    "\n",
    "    # Change column names to clean column names\n",
    "    inspection_locations.columns = clean_col_names\n",
    "\n",
    "    # Reorder columns with lat/lng firs and address in standard order\n",
    "    inspection_locations = inspection_locations.iloc[:,np.r_[0,2,3,1,5,6,4]]\n",
    "\n",
    "    # Rename postal code to snake case\n",
    "    inspection_locations = inspection_locations.rename(columns={\"postalCode\": \"postal_code\"})\n",
    "\n",
    "    # Drop rows missing an address - This is only for the test data.  Live inspection data isn't missing addresses.\n",
    "    inspection_locations = inspection_locations.dropna(subset=['address'])\n",
    "\n",
    "    inspection_locations.to_csv(\"inspection_locations.csv\", index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
